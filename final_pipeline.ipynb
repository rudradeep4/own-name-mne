{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.backends.backend_pdf\n",
    "import glob\n",
    "from autoreject import AutoReject, get_rejection_threshold\n",
    "import eelbrain\n",
    "import seaborn as sns\n",
    "import pingouin as pg\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get .vhdr files\n",
    "A helper function to make the exclusions of certain participants from the analysis easier. Provide subject numbers as list of string in the exclude parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(subjs, file_suffix, exclude):\n",
    "    \n",
    "    for i in range(len(exclude)):\n",
    "        exclude[i] = f'./eeg_data\\\\Rise00{exclude[i]}.{file_suffix}'\n",
    "    \n",
    "    subjs = list(set(subjs) - set(exclude))\n",
    "    \n",
    "    return subjs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename channels\n",
    "Function to rename the channels in the raw files in accordance with the 10-20 standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_channels(raw, channel_names):\n",
    "    channel_names_old = raw.ch_names\n",
    "    channel_dict = dict(zip(channel_names_old, channel_names))\n",
    "    mne.rename_channels(raw.info, mapping=channel_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get events"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Events for subjects 4 onwards\n",
    "A different function is needed to get and clean the events for subjects 4 and above because the stimuli were presented using Python and thus have different marker IDs and encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_events_main(raw):\n",
    "    events_from_annot, event_dict = mne.events_from_annotations(raw)\n",
    "\n",
    "    # Get indices of R11 events with event code 1011 or New Segment indices with event code 99999 and delete them\n",
    "    useless_events = list(filter(lambda i: events_from_annot[:, 2][i] == 99999 or events_from_annot[:, 2][i] == 1011, range(len(events_from_annot[:, 2]))))\n",
    "    events = np.delete(events_from_annot, useless_events, 0)\n",
    "\n",
    "    # Get indices of consective equal events and keep only the 1st one and delete the others\n",
    "    consecutive_equal_events = list(filter(lambda i: events[:, 2][i] == events[:, 2][i+1], range(len(events[:, 2])-1)))\n",
    "    consecutive_equal_events = [index+1 for index in consecutive_equal_events]\n",
    "    events = np.delete(events, consecutive_equal_events, 0)\n",
    "\n",
    "    # If experiment starts with an S event with event code 2, delete it\n",
    "    if events[:, 2][0] == 2:\n",
    "        events = np.delete(events, 0, 0)\n",
    "\n",
    "    # Change S event so it takes event code from R events (for e.g.- if R3 is followed by S2, we will change it to S3)\n",
    "    for i in range(0, len(events), 2):\n",
    "        events[i+1][2] = events[i][2]\n",
    "\n",
    "    # Extract S events into different array\n",
    "    s_events = events[1::2]\n",
    "\n",
    "    return s_events"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Events for subjects 1, 2 and 3\n",
    "A different function is needed to get and clean the events for subjects 1, 2 and 3 because the stimuli were presented using the software Presentation as compared to Python for the rest of the subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_events_before_4(raw):\n",
    "    events_from_annot, event_dict = mne.events_from_annotations(raw)\n",
    "\n",
    "    # Get indices of R11 events with event code 1011 or New Segment indices with event code 99999 and delete them\n",
    "    useless_events = list(filter(lambda i: events_from_annot[:, 2][i] == 99999 or events_from_annot[:, 2][i] == 1011 or events_from_annot[:, 2][i] == 2 or events_from_annot[:, 2][i] == 6, range(len(events_from_annot[:, 2]))))\n",
    "    events = np.delete(events_from_annot, useless_events, 0)\n",
    "\n",
    "    for i in range(len(events[:, 2])):\n",
    "        if events[:, 2][i] == 1004 or events[:, 2][i] == 1008:\n",
    "            events[:, 2][i] = 1001\n",
    "        elif  events[:, 2][i] == 1012:\n",
    "            events[:, 2][i] = 1002\n",
    "        elif events[:, 2][i] == 1024:\n",
    "            events[:, 2][i] = 1003\n",
    "        elif events[:, 2][i] == 1028:\n",
    "            events[:, 2][i] = 1004\n",
    "\n",
    "    return events"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Stimulus Channel to Raw\n",
    "We create a stimulus channel in the raw data to add the events that were extracted and cleaned above to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stim_channel(raw, events):\n",
    "    raw.load_data()\n",
    "    stim_data = np.zeros((1, len(raw.times)))\n",
    "\n",
    "    # Add stimulus channel in 'raw' object's info class\n",
    "    info = mne.create_info(['STI'], raw.info['sfreq'], ['stim'])\n",
    "    stim_raw = mne.io.RawArray(stim_data, info)\n",
    "    raw.add_channels([stim_raw], force_update_info=True)\n",
    "\n",
    "    # Add events extracted from annotations to the stimulus channel\n",
    "    raw.add_events(events, stim_channel='STI')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop Raw Data\n",
    "Remove parts of the raw data that are unnecessary for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_data(raw, t_from, t_to):\n",
    "    first_event_time = mne.find_events(raw)[0][0]\n",
    "    last_event_time = mne.find_events(raw)[-1][0]\n",
    "    print(first_event_time, ' ', last_event_time)\n",
    "\n",
    "    part_to_remove_from_beginning = (first_event_time - abs(t_from*500))/1000\n",
    "    part_to_remove_from_end = (last_event_time + abs(t_to*5000))/1000\n",
    "    raw.crop(part_to_remove_from_beginning, part_to_remove_from_end)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Filters\n",
    "Bandpass and notch filters are applied to the raw signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filter(raw):\n",
    "    # Soft bandpass Butterworth filter \n",
    "    iir_params = dict(  order=2, \n",
    "                        ftype='butter', \n",
    "                        output='sos'\n",
    "                    )\n",
    "    iir_params = mne.filter.construct_iir_filter(   iir_params, \n",
    "                                                    f_pass=[0.1, 30], \n",
    "                                                    f_stop=None, \n",
    "                                                    sfreq=1000, \n",
    "                                                    btype='bandpass', \n",
    "                                                    return_copy=False\n",
    "                                                )\n",
    "    raw.filter(0.1, 30, method='iir', iir_params=iir_params)\n",
    "\n",
    "    # Notch filter\n",
    "    raw.notch_filter(   freqs=np.arange(50, 251, 50), \n",
    "                        method='fir', \n",
    "                        fir_design='firwin2'\n",
    "                    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoreject\n",
    "Repair bad channels and reject bad trials using the autoreject library (https://autoreject.github.io/stable/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_autoreject(epochs):\n",
    "    ar = AutoReject(n_interpolate=[1, 2, 3, 4], random_state=11, n_jobs=1, verbose=True)\n",
    "    ar.fit(epochs) \n",
    "    epochs_ar, reject_log = ar.transform(epochs, return_log=True)\n",
    "\n",
    "    return epochs_ar, reject_log"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICA\n",
    "Fit and run ICA on epochs. We reject ICs that match the EOG pattern by matching with Fp1 as proxy for an EOG channel (since we didn't have EOG electrodes in the experiment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ica(epochs, reject_log, eog_proxy):\n",
    "    ica = mne.preprocessing.ICA(random_state=99)\n",
    "    ica.fit(epochs[~reject_log.bad_epochs])\n",
    "\n",
    "    # Find which ICs match the EOG pattern\n",
    "    eog_indices, eog_scores = ica.find_bads_eog(epochs[~reject_log.bad_epochs], ch_name=eog_proxy)\n",
    "    print(f'**************** Automatically found EOG artifact ICA components: {eog_indices} ****************')\n",
    "\n",
    "    # # Find which ICs match the EMG pattern\n",
    "    # muscle_idx_auto, scores = ica.find_bads_muscle(epochs[~reject_log.bad_epochs])\n",
    "    # print(f'**************** Automatically found muscle artifact ICA components: {muscle_idx_auto} ****************')\n",
    "\n",
    "    ica.exclude = eog_indices\n",
    "\n",
    "    ica.plot_overlay(epochs.average(), exclude=ica.exclude)\n",
    "    ica.apply(epochs, exclude=ica.exclude)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Evokeds from Epochs\n",
    "Evokeds are MNE objects that contain data averaged over different conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_evokeds(epochs, subj):\n",
    "    # Create Evoked object from epochs (an Evoked object contains the average data over all epochs)\n",
    "    evoked_standard = epochs['1001'].average()\n",
    "    evoked_neutral = epochs['1002'].average()\n",
    "    evoked_rise = epochs['1003'].average()\n",
    "    evoked_fall = epochs['1004'].average()\n",
    "\n",
    "    mne.write_evokeds('./analysis/'+subj[17:19]+'-ave.fif', [evoked_standard, evoked_neutral, evoked_rise, evoked_fall], overwrite=True)\n",
    "\n",
    "    evokeds = dict(standard=evoked_standard, neutral=evoked_neutral, rise=evoked_rise, fall=evoked_fall)\n",
    "\n",
    "    return evokeds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ERPs\n",
    "Function to plot ERPs for neutral, rise and fall conditions in the desired channels, in this case, Fz, Pz, Oz, AFz, POz, CPz, FCz, Cz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_erps(evokeds, subj, channels):\n",
    "    # Create PDF file in which to save all plots\n",
    "    with matplotlib.backends.backend_pdf.PdfPages('./analysis/'+subj[17:19]+'-plots.pdf') as pdf:\n",
    "    \n",
    "        for channel in channels:\n",
    "            fig = mne.viz.plot_compare_evokeds(evokeds, picks=channel, combine=None, time_unit='ms', ylim=dict(eeg=[-10, 10]), invert_y=True,\n",
    "                                            colors=dict(standard='black', neutral='red', rise='blue', fall='green'), \n",
    "                                            styles={'standard': {'linewidth': 1}, 'neutral': {'linewidth': 1}, 'rise': {'linewidth': 1}, 'fall': {'linewidth': 1}})\n",
    "            # Save plot to PDF\n",
    "            pdf.savefig(fig[0])\n",
    "            plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "Declare the variables that are used often in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_files = glob.glob('./eeg_data/Rise*.vhdr')\n",
    "subjs_all = get_files(eeg_files, '.vhdr', exclude=[])\n",
    "# subjs_excl = get_files(eeg_files, exclude=['2', '3', '22', '25', '33', '34', '36'])\n",
    "\n",
    "channel_names = [\n",
    "                    'Fp1','Fz','F3','F7','FT9','FC5','FC1','C3','T7','TP9','CP5','CP1','Pz','P3','P7','O1','Oz','O2','P4','P8','TP10','CP6',\n",
    "                    'CP2','C4','T8','FT10','FC6','FC2','F4','F8','Fp2', 'AF7','AF3','AFz','F1','F5','FT7','FC3','C1','C5','TP7','CP3','P1','P5',\n",
    "                    'PO7','PO3','POz','PO4','PO8','P6','P2','CPz','CP4','TP8','C6','C2','FC4','FT8','F6','AF8','AF4','F2','FCz', 'Cz'\n",
    "                ]\n",
    "\n",
    "montage = mne.channels.make_standard_montage('easycap-M1')\n",
    "\n",
    "epoch_limits = [-0.1, 0.6]\n",
    "\n",
    "baseline = (-0.1, 0)\n",
    "\n",
    "channels_to_vis = ['Fz', 'Pz', 'Oz', 'AFz', 'POz', 'CPz', 'FCz', 'Cz']\n",
    "\n",
    "output_dir = './analysis/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call Functions\n",
    "Iterate over all subjects and call the functions in the pipeline for each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subj in subjs_all:\n",
    "    raw = mne.io.read_raw_brainvision(subj, verbose=False)\n",
    "\n",
    "    rename_channels(raw, channel_names)\n",
    "    \n",
    "    raw.set_montage(montage)\n",
    "    raw.plot_sensors(show_names=True)\n",
    "\n",
    "    if int(subj[17:19]) >= 4:\n",
    "        events = get_events_main(raw)\n",
    "    else:\n",
    "        events = get_events_before_4(raw)\n",
    "        \n",
    "    create_stim_channel(raw, events)\n",
    "\n",
    "    crop_data(raw, epoch_limits[0], epoch_limits[1])\n",
    "\n",
    "    apply_filter(raw)\n",
    "\n",
    "    mne.add_reference_channels(raw, 'Cz', copy=False)\n",
    "    mne.set_eeg_reference(raw, ref_channels='average', projection=True)\n",
    "    raw.apply_proj()\n",
    "\n",
    "    raw.set_montage(montage)\n",
    "\n",
    "    epochs = mne.Epochs(raw, events, tmin=epoch_limits[0], tmax=epoch_limits[1], preload=True, baseline=None)\n",
    "\n",
    "    epochs_ar, reject_log = run_autoreject(epochs)\n",
    "    run_ica(epochs, reject_log, 'Fp1')\n",
    "\n",
    "    epochs.apply_baseline(baseline=baseline)\n",
    "    \n",
    "    epochs_ar = run_autoreject(epochs)\n",
    "\n",
    "    epochs_ar.save('./analysis/'+subj[17:19]+'-epo.fif', overwrite=True)\n",
    "\n",
    "    evokeds = create_evokeds(epochs_ar, subj)\n",
    "    \n",
    "    plot_erps(evokeds, subj, channels_to_vis)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grand Average"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Evokeds\n",
    "Combine the evokeds object for each condition for each participant to get grand average of each condition over all subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grand_average(subjs, outfile, exclude=[]):\n",
    "    standard_subjs = []\n",
    "    neutral_subjs = []\n",
    "    rise_subjs = []\n",
    "    fall_subjs = []\n",
    "\n",
    "    subjs = get_files(subjs, '-ave.fif', exclude=exclude)\n",
    "    \n",
    "    # Separate evoked objects of all subjects into different conditions\n",
    "    for subj in subjs:\n",
    "        standard_subjs.append(mne.read_evokeds(subj, condition='1001'))\n",
    "        neutral_subjs.append(mne.read_evokeds(subj, condition='1002'))\n",
    "        rise_subjs.append(mne.read_evokeds(subj, condition='1003'))\n",
    "        fall_subjs.append(mne.read_evokeds(subj, condition='1004'))\n",
    "\n",
    "    # Combine evoked objects in each condition\n",
    "    standard_combined = mne.combine_evoked(standard_subjs, weights='nave')\n",
    "    neutral_combined = mne.combine_evoked(neutral_subjs, weights='nave')\n",
    "    rise_combined = mne.combine_evoked(rise_subjs, weights='nave')\n",
    "    fall_combined = mne.combine_evoked(fall_subjs, weights='nave')\n",
    "\n",
    "    # Save combined evoked objects of all conditions into file\n",
    "    mne.write_evokeds(f'./analysis/{outfile}', [standard_combined, neutral_combined, rise_combined, fall_combined], overwrite=True)\n",
    "\n",
    "    evokeds = dict(standard=standard_combined, neutral=neutral_combined, rise=rise_combined, fall=fall_combined)\n",
    "\n",
    "    return evokeds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Grand Average\n",
    "Plot the timecourse for the averaged signal for each condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grand_average(evokeds, outfile, channels=[]):\n",
    "    # Create PDF file in which to save all plots\n",
    "    with matplotlib.backends.backend_pdf.PdfPages(f'./analysis/{outfile}') as pdf:\n",
    "    \n",
    "        for channel in channels:\n",
    "            fig = mne.viz.plot_compare_evokeds(evokeds, picks=channel, combine=None, time_unit='ms', ylim=dict(eeg=[-5, 5]), invert_y=True,\n",
    "                                            colors=dict(standard='black', neutral='red', rise='blue', fall='green'), \n",
    "                                            styles={'standard': {'linewidth': 1}, 'neutral': {'linewidth': 1}, 'rise': {'linewidth': 1}, 'fall': {'linewidth': 1}})\n",
    "            # Save plot to PDF\n",
    "            pdf.savefig(fig[0])\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of evoked objects of all subjects\n",
    "all_subj_evoked = glob.glob('./analysis/Rise*-ave.fif')\n",
    "\n",
    "# Get grand average of all subjects\n",
    "evokeds = get_grand_average(all_subj_evoked, 'grand-ave.fif', exclude=[])\n",
    "# Get grand average with subjects 22, 25, 33, 34 and 36 excluded\n",
    "# evokeds_excluded = get_grand_average(all_subj_evoked, 'excl-grand-ave.fif', exclude=['2', '3', '22', '25', '33', '34', '36'])\n",
    "\n",
    "# Plot channels Fz, Pz, Oz, AFz, POz, CPz, FCz, Cz for all subjects\n",
    "plot_grand_average(evokeds, 'grand-ave-plots.pdf', channels=channels_to_vis)\n",
    "# Plot channels Fz, Pz, Oz, AFz, POz, CPz, FCz, Cz for all subjects excluding 22, 25, 33, 34 and 36\n",
    "# plot_grand_average(evokeds_excluded, 'excl-grand-ave.fif', channels=['Fz', 'Pz', 'Oz', 'AFz', 'POz', 'CPz', 'FCz', 'Cz'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset\n",
    "From evokeds data of each subject, construct a pandas dataframe over which to calculate statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(subjs, events_id, ch, time_win, peak_func):\n",
    "\n",
    "    data_Pz = []\n",
    "\n",
    "    for subj in subjs:\n",
    "        for event_name in events_id:\n",
    "            evk = mne.read_evokeds(subj, condition=event_name, verbose=False)\n",
    "\n",
    "            evk.pick(ch)\n",
    "\n",
    "            data = evk.data[0][time_win[0]:time_win[1]]\n",
    "\n",
    "            if peak_func == 'auc':\n",
    "                data_Pz.append(np.sum(np.abs(data)))\n",
    "            elif peak_func == 'peak':\n",
    "                data[data < 0] = 0\n",
    "                data_Pz.append(np.amax(data))\n",
    "\n",
    "    subjs_for_df = sorted([int(name[17: 19]) for name in subjs])\n",
    "\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "            'Subject': np.repeat(subjs_for_df, len(events_id)),\n",
    "            'Condition': np.tile(['Neutral', 'Rise', 'Fall'], len(subjs_for_df)),\n",
    "            'uV': data_Pz\n",
    "        })\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evokeds_files = glob.glob('./analysis/Rise*-ave.fif')\n",
    "\n",
    "subjs_all = get_files(evokeds_files, exclude=[])\n",
    "# subjs_excl = get_files(evokeds_files, exclude=['2', '3', '22', '25', '33', '34', '36'])\n",
    "\n",
    "df = create_df  (\n",
    "                    subjs_all, \n",
    "                    ['1002', '1003', '1004'], \n",
    "                    'Pz', \n",
    "                    [220, 350], \n",
    "                    'auc'\n",
    "                )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Condition Averages\n",
    "Using the dataframe, plot graphs comparing each condition in terms of their peak amplitude (peak) or area under curve (auc). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(x='Condition', y = 'uV', units= \"Subject\", estimator=None, data = df, alpha=0.3, hue=\"Subject\", legend=False)\n",
    "sns.stripplot(x=\"Condition\", y=\"uV\", hue=\"Condition\", data=df, jitter=False, alpha =0.3)\n",
    "ax = sns.pointplot(x='Condition', y = 'uV', data = df)\n",
    "ax.set_title('CPz AUC between Conditions w Subj. Excl.')\n",
    "sns.despine()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeated-measures ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeated measure ANOVA\n",
    "pg.rm_anova(dv='uV', \n",
    "               within='Condition', \n",
    "               subject=\"Subject\",\n",
    "               data=df,\n",
    "               detailed=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paired t-tests (Rise-Fall and Rise-Neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paired t-test between Rise & Neutral\n",
    "pg.ttest(x=df[df.Condition=='Rise'].uV, y=df[df.Condition=='Neutral'].uV, paired=True)\n",
    "\n",
    "# Paired t-test between Rise & Fall\n",
    "pg.ttest(x=df[df.Condition=='Rise'].uV, y=df[df.Condition=='Fall'].uV, paired=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatio-temporal Cluster Permutation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disable Multiprocessing (only for Windows)\n",
    "There is an issue with multiprocessing in Windows which causes problems with the permutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eelbrain.configure(n_workers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(subjs, exclude):\n",
    "    \n",
    "    for i in range(len(exclude)):\n",
    "        exclude[i] = f'./analysis\\\\Rise00{exclude[i]}-epo.fif'\n",
    "    \n",
    "    subjs = list(set(subjs) - set(exclude))\n",
    "    \n",
    "    return subjs\n",
    "\n",
    "epoch_files = glob.glob('./analysis/Rise*-epo.fif')\n",
    "\n",
    "subjs_all = get_files(epoch_files, '-epo.fif', exclude=[])\n",
    "# subjs_excl = get_files(epoch_files, exclude=['2', '3', '22', '25', '33', '34', '36'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conds_to_compare = ['Rise', 'Fall']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Eelbrain Dataset\n",
    "Create an Eelbrain dataset object that contains epoch data for each subject in each condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = eelbrain.Dataset()\n",
    "event_dict = {\n",
    "                # '1002': 'Neutral', \n",
    "                '1003': 'Rise',\n",
    "                '1004': 'Fall'\n",
    "            }\n",
    "\n",
    "rows = []\n",
    "for subj in subjs_all:\n",
    "    for key, val in event_dict.items():\n",
    "        subject = int(subj[17: 19])\n",
    "        condition = val\n",
    "        eeg = eelbrain.load.fiff.epochs_ndvar(mne.read_epochs(subj, verbose=False)[key], data='eeg')\n",
    "        rows.append([subject, condition, eeg.mean('case')])\n",
    "\n",
    "ds = eelbrain.Dataset.from_caselist(['subject', 'condition', 'eeg'], rows)\n",
    "ds['subject'].random = True\n",
    "print(ds.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = eelbrain.plot.SensorMap(ds['eeg'], connectivity=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct Spatio-Temporal Cluster Permutation Test\n",
    "The minimum temporal extent of the clusters found is set to 800ms to avoid getting very small clusters and clusters consisting of only 1 or 2 sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = eelbrain.testnd.TTestRelated(\n",
    "    'eeg', 'condition', conds_to_compare[0], conds_to_compare[1], match='subject', ds=ds,\n",
    "    pmin=0.05,  # Use uncorrected p = 0.05 as threshold for forming clusters\n",
    "    tstart=0.100,  # Find clusters in the time window from 100 ...\n",
    "    tstop=0.600,  # ... to 600 ms\n",
    "    mintime=0.1,\n",
    "    # minsource=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = eelbrain.plot.TopoButterfly(res, clip='circle')\n",
    "p.plot_colorbar()\n",
    "p.set_time(0.470)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Clusters\n",
    "Clusters above a thershold of 0.05 are selected and returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = res.find_clusters(0.05)\n",
    "print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = clusters['id'][:]\n",
    "\n",
    "cluster_ndvars = []\n",
    "\n",
    "for i in range(len(a)):\n",
    "    cluster = res.cluster(a[i])\n",
    "    cluster_ndvars.append(cluster)\n",
    "    p = eelbrain.plot.TopoArray(cluster, interpolation='nearest')\n",
    "    p.set_topo_ts(0.2, 0.3, 0.4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Cluster Timecourse\n",
    "Returns plots for the timecourse of the sensors found in each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = []\n",
    "\n",
    "for i in range(len(cluster_ndvars)):\n",
    "\n",
    "    # sensor x sample plot with topogrpahy\n",
    "    mask = cluster_ndvars[i] != 0\n",
    "    masks.append(mask)\n",
    "    p = eelbrain.plot.TopoArray(mask, cmap='Wistia')\n",
    "    p.set_topo_ts(.280, 0.380, 0.470)\n",
    "\n",
    "    # barplot for magnitude of each condition within a cluster\n",
    "    ds['cluster_mean'] = ds['eeg'].mean(mask)\n",
    "    p = eelbrain.plot.Barplot('cluster_mean', 'condition', match='subject', ds=ds, test=False, title=f'Cluster ID: {clusters[i, \"id\"]}, from {clusters[i, \"tstart\"]} to {clusters[i, \"tstop\"]}')\n",
    "\n",
    "    # topography map for spatial extent of each cluster\n",
    "    roi = mask.any('time')\n",
    "    p = eelbrain.plot.Topomap(roi, cmap='Wistia')\n",
    "\n",
    "    \n",
    "    ds['cluster_timecourse'] = ds['eeg'].mean(roi)\n",
    "    p = eelbrain.plot.UTSStat('cluster_timecourse', 'condition', match='subject', ds=ds, frame='t', title='Compare conditions (all channels within cluster)')\n",
    "    # mark the duration of the spatio-temporal cluster\n",
    "    p.set_clusters(clusters[[i]])\n",
    "\n",
    "    # mark significant sensors in topographic map of difference between conditions\n",
    "    time_window = (clusters[0, 'tstart'], clusters[0, 'tstop'])\n",
    "    c1_topo = res.c1_mean.mean(time=time_window)\n",
    "    c0_topo = res.c0_mean.mean(time=time_window)\n",
    "    diff_topo = res.difference.mean(time=time_window)\n",
    "    p = eelbrain.plot.Topomap([c1_topo, c0_topo, diff_topo], axtitle=[conds_to_compare[0], conds_to_compare[1], f'{conds_to_compare[0]}-{conds_to_compare[1]}'], ncol=3)\n",
    "    p.mark_sensors(roi, -1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal cluster-based test\n",
    "We restrict the spatial dimension to only 2 sensors (Pz and CPz) and conduct a temporal cluster test to find significant clusters in these channels only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['eeg_pz'] = ds['eeg'].sub(sensor='Pz')\n",
    "\n",
    "res_timecoure = eelbrain.testnd.TTestRelated(\n",
    "    'eeg_pz', 'condition', conds_to_compare[0], conds_to_compare[1], match='subject', ds=ds,\n",
    "    pmin=0.05,  # Use uncorrected p = 0.05 as threshold for forming clusters\n",
    "    tstart=0.100,  # Find clusters in the time window from 100 ...\n",
    "    tstop=0.600,  # ... to 600 ms\n",
    "    mintime=0.1\n",
    ")\n",
    "clusters_pz = res_timecoure.find_clusters(0.05)\n",
    "print(clusters_pz)\n",
    "\n",
    "p = eelbrain.plot.UTSStat('eeg_pz', 'condition', match='subject', ds=ds, frame='t', title='Compare conditions (Pz)')\n",
    "p.set_clusters(clusters_pz, y=0.25e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['eeg_cpz'] = ds['eeg'].sub(sensor='CPz')\n",
    "\n",
    "res_timecoure = eelbrain.testnd.TTestRelated(\n",
    "    'eeg_cpz', 'condition', conds_to_compare[0], conds_to_compare[1], match='subject', ds=ds,\n",
    "    pmin=0.05,  # Use uncorrected p = 0.05 as threshold for forming clusters\n",
    "    tstart=0.100,  # Find clusters in the time window from 100 ...\n",
    "    tstop=0.600,  # ... to 600 ms\n",
    "    mintime=0.1\n",
    ")\n",
    "clusters_cpz = res_timecoure.find_clusters(0.05)\n",
    "print(clusters_cpz)\n",
    "\n",
    "p = eelbrain.plot.UTSStat('eeg_cpz', 'condition', match='subject', ds=ds, frame='t', title='Compare conditions (CPz)')\n",
    "p.set_clusters(clusters_cpz, y=0.25e-6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('eelbrain')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:16:33) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "99ceff474ddd88436593420339e3865c681551bf0bfe21dd21eebadbb2bc8b2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
